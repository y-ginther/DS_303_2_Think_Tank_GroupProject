{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project proposal\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. Please answer the following questions as part of your project proposal.\n",
    "\n",
    "2. Write your answers in the *Markdown* cells of the Jupyter notebook. You don't need to write any code, but if you want to, you may use the *Code* cells.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The project proposal is worth 8 points, and is due on **27th January 2023 at 11:59 pm**. \n",
    "\n",
    "5. You must make one submission as a group, and not individually.\n",
    "\n",
    "6. Each team member must have at least **one commit** on the team's github repository. No points will be awarded to the team member(s) with no commits.\n",
    "\n",
    "7. Share the link of your project's GitHub repository [here](https://docs.google.com/spreadsheets/d/1khao3unpj_vsx4kOSg_Zzo77YK1UWL2w73Oa0aAirOo/edit#gid=0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "# 1) Team name\n",
    "Mention your team name.\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b160e",
   "metadata": {},
   "source": [
    "### The Think Tank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fccc9b",
   "metadata": {},
   "source": [
    "# 2) Member names\n",
    "Mention the names of your team members.\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bb854",
   "metadata": {},
   "source": [
    "### Connor Doolan, Rob Hickmott, Yui Ginther, Priya Tha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a6528",
   "metadata": {},
   "source": [
    "# 3) Link to the GitHub repository\n",
    "Share the link of the team's project repository on GitHub.\n",
    "\n",
    "Also, put the link of your project's GitHub repository [here](https://docs.google.com/spreadsheets/d/1khao3unpj_vsx4kOSg_Zzo77YK1UWL2w73Oa0aAirOo/edit#gid=0).\n",
    "\n",
    "We believe there is no harm in having other teams view your GitHub repository. However, if you don't want anyone to see your team's work, you may make the repository *Private* and add your instructor and graduate TA as *Colloborators* in it.\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f534f29",
   "metadata": {},
   "source": [
    "### https://github.com/y-ginther/DS_303_2_Think_Tank_GroupProject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1a490",
   "metadata": {},
   "source": [
    "# 4) Topic\n",
    "Mention the topic of your course project.\n",
    "\n",
    "*(0.25 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f00bb9",
   "metadata": {},
   "source": [
    "### We are creating a project surrounding the National Basketball Association player and team statistics. The idea is to develop a model to predict the winner of any given NBA game."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403cdfb",
   "metadata": {},
   "source": [
    "# 5) Problem statement\n",
    "Explain the problem statement. The problem statement must include:\n",
    "\n",
    "1. The problem\n",
    "\n",
    "2. Is it a regression or classification problem or a combination of both?\n",
    "\n",
    "3. Is it an inference or prediction problem or a combination of both?\n",
    "\n",
    "4. How will you assess model accuracy?\n",
    "\n",
    "  - If it is a classification problem, then which measure(s) will you optimize for your model – precision, recall, false negative rate (FNR), accuracy, ROC-AUC etc., and why?\n",
    "  - If it is a regression problem, then which measure(s) will you optimize for your model – RMSE (Root mean squared error), MAE (mean absolute error), maximum absolute error etc., and why?\n",
    "\n",
    "5. What techniques do you think you may need to use to improve your model? If you have too many variables, some of which are  correlated or collinear, you may need to do variable selection *(techniques for variable selection that you will learn later in the course - stepwise regression, lasso, ridge regression)*. If the variables do not have a linear relationship with the response, or if some of the modeling assumptions are not satisfied, you may need to transform the predictors and/or the response (variable transformation) to obtain a better fit.\n",
    "\n",
    "*(5 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba58dc9b",
   "metadata": {},
   "source": [
    "### What contributes to winning? For our project we plan on creating a linear model that assesses a number of variables in a NBA basketball game and creates a determination which team will win. This problem is a classification problem as  the output variable is a categorical variable indicating whether the team wins or loses. This is also a prediction problem as it attempts to make a future decision whether a team will win or lose based on past information.\n",
    "\n",
    "### There are several metrics that can be used to assess our model’s accuracy. We can access accuracy directly by dividing the number of correct predictions by the total number of predictions to get a proportion. We can also decide precision by dividing the number of true positive predictions by the number of true positive predictions plus the number of false positive predictions. Next we can decide recall by dividing the number of true positive predictions by the number of true positive predictions plus the number of false negative predictions. Lastly, as a more holistic metric, we can determine the model’s F1 score, a measure that balances precision and recall for binary classification.\n",
    "\n",
    "### In this model it is most likely beneficial to optimize for ROC-AUC, which balances the trade-off between precision and recall in order to make the most accurate binary decision for the binary classification at different thresholds.\n",
    "\n",
    "### Overall, we will need to explore the variables in their relationship to the model as a whole in order to get a better understanding of collinearity and correlation to better optimize variable selection. It is also important to test different models and different feature sets, and carefully evaluate their performance using the appropriate evaluation metrics to find the best model for our purposes. To do this will have to attempt different strategies such as regularization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2d4f2",
   "metadata": {},
   "source": [
    "# 6) Data sources\n",
    "\n",
    "What data sources will you use, and how will the data help answer the questions? Explain.\n",
    "\n",
    "If the data is open source, share the link of the data.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e65b47",
   "metadata": {},
   "source": [
    "### We are using a dataset compiled from https://www.nba.com/stats. This data source contains a significant amount of information that will help answer overarching questions and develop the best model possible. Important information includes 1) summary statistics of every game since the 2004 season, 2) relevant player statistics for each game, and 3) season statistics for the relevant teams such as win percentage and conference rank, again for each game. We will focus on data from the last 3 years as data previous to that would be unhelpful for our model. To be able to assess the accuracy of our model, we will use the most recent year of data as ‘Test Data’ and previous years as ‘Training Data’. Inspiration and potential csv files were found at https://www.kaggle.com/datasets/nathanlauga/nba-games?resource=download&select=ranking.csv."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a845f",
   "metadata": {},
   "source": [
    "# 7) Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "Who are the stakeholders, and how will your project benefit them? Explain.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a5550",
   "metadata": {},
   "source": [
    "### Our stakeholders are primarily basketball team coaches and staff, and secondarily basketball commentators and pundits. For coaches and support staff, our model can help them prioritize what aspects of the game to improve for their team. With that, coaches can be more effective in practices and lead their teams to more wins. For commentators and those whose job it is to talk about the game or create content about the NBA, understanding the relevant game statistics to highlight to casual viewers can make their analysis more effective and engaging. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6d0f26",
   "metadata": {},
   "source": [
    "### A separate group of stakeholders includes the sports betting community. Developing a model to determine a team's likelihood of winning in a given game can be a reliable resource allowing bettors to select the best bets and make money."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e41b2a",
   "metadata": {},
   "source": [
    "# 8) Results\n",
    "What kind of results do you expect? \n",
    "\n",
    "How much accuracy is required / desired in your model (based on the metric(s) chosen in question 5), such that it is useful to the stakeholders and why?\n",
    "\n",
    "**Hint:** If it is a classification model, then your model must be at least better than random classification. If it is a regression model, then your model must be at least better than trivial models, such as the one with only the intercept term.\n",
    "\n",
    "*(0.5 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00805c",
   "metadata": {},
   "source": [
    "### In our preliminary research, the best models we’ve found successfully predict the winners of NBA games roughly between 65-70% of the time. For our classification model, we are aiming to significantly improve upon random classification (50%) and successfully predict NBA games at a rate of 65%. This success rate should make our model competitive with other projects out there, so that stakeholders can rely on our model and value from its predictions. This goal is subject to change following more research and development of our model, and finding realistic success rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c874b4f",
   "metadata": {},
   "source": [
    "# 9) Work-split\n",
    "How do you plan to split the project work amongst individual team members?\n",
    "\n",
    "*(0.25 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010a5aa",
   "metadata": {},
   "source": [
    "### We will split up the work so that one person tackles the data cleaning and preparation, one person begins to develop the model, then the group looks at the work, offers feedback and collaborate to choose variables, and then one conducts outlier treatment, one addresses overfitting, and one applies the model on test data for prediction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
